<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="ELION Lab - Advancing Language Model Research for a Better Future. Explore our cutting-edge research in NLP, machine learning, and AI.">
    <meta name="keywords" content="language models, NLP, natural language processing, machine learning, AI research, deep learning">
    <meta name="author" content="ELION Lab">

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-8LWM0YYTQ3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-8LWM0YYTQ3');
    </script>

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="ELION Lab - Language Model Research">
    <meta property="og:description" content="Advancing Language Model Research for a Better Future">
    <meta property="og:image" content="assets/images/logos/og-image.png">

    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="assets/images/logos/favicon.svg">

    <!-- Google Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=Playfair+Display:wght@600;700&display=swap" rel="stylesheet">
    
    <!-- Stylesheet -->
    <link rel="stylesheet" href="assets/css/style.css">
    
    <title>ELION Lab - Language Model Research</title>
</head>
<body>
    <!-- Header -->
    <header class="header">
        <div class="container">
            <a href="index.html" class="logo">
                <img src="assets/images/logos/logo.png" alt="ELION Lab Logo">
                <span>ELION Lab</span>
            </a>
            
            <button class="menu-toggle" aria-label="Toggle navigation menu" aria-expanded="false">
                <span></span>
                <span></span>
                <span></span>
            </button>
            
            <nav>
                <ul class="nav-menu" aria-hidden="true">
                    <li><a href="index.html" class="active">Home</a></li>
                    <li><a href="about.html">About</a></li>
                    <li><a href="publications.html">Publications</a></li>
                    <li><a href="team.html">Team</a></li>
                    <li><a href="contact.html">Contact</a></li>
                </ul>
            </nav>
        </div>
    </header>

    <!-- Main Content -->
    <main>
        <!-- Hero Section -->
        <section class="hero">
            <div class="container">
                <h1>ELION Lab</h1>
                <p class="subtitle" style="font-size: 1.2rem; margin-bottom: 0.5rem;">
                    <strong>Language Intelligence & Representation</strong>
                </p>
                <p class="subtitle" style="font-size: 0.9em;">
                    Our research group explores the frontiers of natural language processing and AI systems, guided by the vision of <strong>E</strong>lucidating <strong>L</strong>anguage <strong>I</strong>ntelligence & Representati<strong>ON</strong> (ELION), to understand how language models represent knowledge, reason, and generate meaning toward interpretable, controllable, and trustworthy language intelligence for real-world interaction.
                </p>
                <div class="hero-buttons">
                    <a href="publications.html" class="btn btn-primary">Our Research</a>
                    <a href="about.html" class="btn btn-secondary">Learn More</a>
                </div>
            </div>
        </section>

        <!-- Research Areas -->
        <section class="section">
            <div class="container">
                <div class="section-header">
                    <h2>Research Areas</h2>
                    <p><strong>Language</strong> is the most fundamental modality of AI, and <strong>Language Models</strong> are the ideal AI systems for connecting knowledge across disciplines. Toward the vision of <strong><em>All Languages, One Mind</em></strong>, we focus on the following research topics.</p>
                </div>

                <div class="grid grid-3">
                    <div class="card feature-card">
                        <div class="feature-icon">üß†</div>
                        <h3 class="feature-title">Language Models & World Models</h3>
                        <p class="feature-text">
                            We develop and analyze language models to study how scale, structure, and representations support reasoning, generalization, controllability, and world modeling.
                        </p>
                    </div>

                    <div class="card feature-card">
                        <div class="feature-icon">üí≠</div>
                        <h3 class="feature-title">Thinking & Reasoning</h3>
                        <p class="feature-text">
                            We study the internal representations and processes that enable language models to perform multi-step thinking and reasoning, aiming to interpret how conclusions are formed and fail.
                        </p>
                    </div>

                    <div class="card feature-card">
                        <div class="feature-icon">üîç</div>
                        <h3 class="feature-title">Hallucination Detection & Mitigation</h3>
                        <p class="feature-text">
                            We investigate hallucination as a representational and epistemic failure in language models, developing methods to detect, analyze, and mitigate ungrounded or misleading generations.
                        </p>
                    </div>

                    <div class="card feature-card">
                        <div class="feature-icon">‚úèÔ∏è</div>
                        <h3 class="feature-title">Model Editing</h3>
                        <p class="feature-text">
                            We explore model editing as a means of modifying internal knowledge representations, enabling correction, updating, and control of language model behavior without retraining.
                        </p>
                    </div>

                    <div class="card feature-card">
                        <div class="feature-icon">üåê</div>
                        <h3 class="feature-title">Multilingual & Multimodality</h3>
                        <p class="feature-text">
                            We study how language models represent and align meaning across languages and modalities, with the goal of building unified models that generalize beyond linguistic and modal boundaries.
                        </p>
                    </div>

                    <div class="card feature-card">
                        <div class="feature-icon">ü§ñ</div>
                        <h3 class="feature-title">AI Agents</h3>
                        <p class="feature-text">
                            We design and analyze language-model-based AI agents, focusing on how internal representations support planning, decision-making, and interaction in dynamic environments.
                        </p>
                    </div>
                </div>
            </div>
        </section>

        <!-- Join Our Research Team -->
        <section class="section section-alt">
            <div class="container">
                <div class="section-header">
                    <h2 style="font-size: 2.5rem;">NOW HIRING!</h2>
                </div>

                <div class="card" style="padding: var(--spacing-xl);">
                    <h3 style="text-align: center; margin-bottom: var(--spacing-xl);">Ongoing Projects</h3>
                    <div style="margin-bottom: var(--spacing-lg);">
                        <h4>1. Continual Representation Learning in Language Models</h4>
                        <p style="margin-left: var(--spacing-md); color: var(--text-secondary);">
                            We study how language models can continuously update and refine their internal representations over time, enabling lifelong learning without forgetting previously acquired knowledge.
                        </p>
                    </div>

                    <div style="margin-bottom: var(--spacing-lg);">
                        <h4>2. Reducing Hallucination in Multi-Agent Systems</h4>
                        <p style="margin-left: var(--spacing-md); color: var(--text-secondary);">
                            We investigate why hallucinations emerge in multi-agent interactions and develop methods to analyze, detect, and reduce ungrounded generation in collaborative language systems.
                        </p>
                    </div>

                    <div style="margin-bottom: var(--spacing-lg);">
                        <h4>3. Anti-Scalability in Language Model Reasoning</h4>
                        <p style="margin-left: var(--spacing-md); color: var(--text-secondary);">
                            We explore the limits of scaling for reasoning, asking when and why larger language models fail to reason better, and what alternative mechanisms are needed beyond scale.
                        </p>
                    </div>

                    <div style="margin-bottom: var(--spacing-lg);">
                        <h4>4. Multimodal Language Modeling and World Understanding</h4>
                        <p style="margin-left: var(--spacing-md); color: var(--text-secondary);">
                            We study how language models integrate vision and other modalities to build world models, enabling reasoning about physical and social contexts beyond text alone.
                        </p>
                    </div>

                    <div style="margin-bottom: var(--spacing-lg);">
                        <h4>5. World-Interactive Data Augmentation</h4>
                        <p style="margin-left: var(--spacing-md); color: var(--text-secondary);">
                            As online data becomes increasingly saturated, we explore world-interactive data augmentation, creating high-level reasoning and multidimensional language data through interaction with real-world environments.
                        </p>
                    </div>
                </div>

                <div class="text-center" style="margin-top: var(--spacing-xl);">
                    <p style="margin-bottom: var(--spacing-md); font-size: 1.3rem;"><strong>We are now looking for talented M.S/Ph.D students, and research interns.</strong></p>
                    <a href="https://forms.gle/hnbmCB3afuWKgrKD6" target="_blank" class="btn btn-primary">APPLY</a>
                </div>
            </div>
        </section>

        <!-- Latest News -->
        <section class="section">
            <div class="container">
                <div class="section-header">
                    <h2>Latest News</h2>
                    <p>Stay updated with our recent achievements and announcements.</p>
                </div>

                <div class="card" style="padding: var(--spacing-xl);">
                    <ul style="list-style: none; padding: 0; margin: 0;">
                        <li style="padding: var(--spacing-md) 0; border-bottom: 1px solid var(--border-color);">
                            <span class="publication-year">Mar 2026</span>
                            üéâ <strong>Established the ELION Lab at Konkuk University</strong>
                        </li>
                        <li style="padding: var(--spacing-md) 0; border-bottom: 1px solid var(--border-color);">
                            <span class="publication-year">Aug 2025</span>
                            üî• <strong>5 papers</strong> are accepted at <strong>EMNLP 2025</strong>.
                        </li>
                        <li style="padding: var(--spacing-md) 0; border-bottom: 1px solid var(--border-color);">
                            <span class="publication-year">May 2025</span>
                            üî• <strong>1 paper</strong> is accepted at <strong>ACL 2025</strong>.
                        </li>
                        <li style="padding: var(--spacing-md) 0; border-bottom: 1px solid var(--border-color);">
                            <span class="publication-year">Feb 2025</span>
                            üî• <strong>1 paper</strong> is accepted at <strong>ICLR 2025</strong>.
                        </li>
                        <li style="padding: var(--spacing-md) 0;">
                            <span class="publication-year">Feb 2025</span>
                            üî• <strong>2 papers</strong> are accepted at <strong>NAACL 2025</strong>.
                        </li>
                    </ul>
                </div>
            </div>
        </section>

        <!-- Featured Publications -->
        <section class="section">
            <div class="container">
                <div class="section-header">
                    <h2>Featured Publications</h2>
                    <p>Selected recent papers from our research group.</p>
                </div>

                <div class="card">
                    <div class="publication-item">
                        <span class="publication-year">EMNLP 2025</span>
                        <h3 class="publication-title">üåü The Impact of Negated Text on Hallucination with Large Language Models</h3>
                        <p class="publication-authors"><strong>Jaehyung Seo</strong>, Hyeonseok Moon, Heuiseok Lim*</p>
                        <p class="publication-venue">Empirical Methods in Natural Language Processing (EMNLP), 2025</p>
                        <div class="publication-links">
                            <a href="https://aclanthology.org/2025.emnlp-main.684/" target="_blank">Paper</a>
                        </div>
                    </div>

                    <div class="publication-item">
                        <span class="publication-year">EMNLP 2025 Findings</span>
                        <h3 class="publication-title">üåü KoLEG: On-the-Fly Korean Legal Knowledge Editing with Continuous Retrieval</h3>
                        <p class="publication-authors"><strong>Jaehyung Seo</strong>, Dahyun Jung, Jaewook Lee, Yongchan Chun, Dongjun Kim, Hwijung Ryu, Donghoon Shin, Heuiseok Lim*</p>
                        <p class="publication-venue">Empirical Methods in Natural Language Processing (EMNLP) Findings, 2025</p>
                        <div class="publication-links">
                            <a href="https://aclanthology.org/2025.findings-emnlp.489/" target="_blank">Paper</a>
                        </div>
                    </div>

                    <div class="publication-item">
                        <span class="publication-year">EMNLP 2025</span>
                        <h3 class="publication-title">üåü MultiDocFusion: Hierarchical and Multimodal Chunking Pipeline for Enhanced RAG on Long Industrial Documents</h3>
                        <p class="publication-authors">Joong Min Shin, Chanjun Park, Jeongbae Park, <strong>Jaehyung Seo</strong>*, Heuiseok Lim*</p>
                        <p class="publication-venue">Empirical Methods in Natural Language Processing (EMNLP), 2025</p>
                        <div class="publication-links">
                            <a href="https://aclanthology.org/2025.emnlp-main.1062/" target="_blank">Paper</a>
                        </div>
                    </div>

                    <div class="publication-item">
                        <span class="publication-year">EMNLP 2025</span>
                        <h3 class="publication-title">üåü Metric Calculating Benchmark: Code-Verifiable Complicate Instruction Following Benchmark for Large Language Models</h3>
                        <p class="publication-authors">Hyeonseok Moon, Seongtae Hong, <strong>Jaehyung Seo</strong>*, Heuiseok Lim*</p>
                        <p class="publication-venue">Empirical Methods in Natural Language Processing (EMNLP), 2025</p>
                        <div class="publication-links">
                            <a href="https://aclanthology.org/2025.emnlp-main.1051/" target="_blank">Paper</a>
                        </div>
                    </div>

                    <div class="publication-item">
                        <span class="publication-year">ICLR 2025</span>
                        <h3 class="publication-title">üåü K-HALU: Multiple Answer Korean Hallucination Benchmark for Large Language Models</h3>
                        <p class="publication-authors"><strong>Jaehyung Seo</strong>, Heuiseok Lim*</p>
                        <p class="publication-venue">International Conference on Learning Representations (ICLR), 2025</p>
                        <div class="publication-links">
                            <a href="https://openreview.net/forum?id=VnLhUogHYE" target="_blank">Paper</a>
                        </div>
                    </div>

                    <div class="publication-item">
                        <span class="publication-year">HCLT 2024 üèÜ Best Paper</span>
                        <h3 class="publication-title">üåü Post-negation Text Induce New Hallucinations in Large Language Models</h3>
                        <p class="publication-authors"><strong>Jaehyung Seo</strong>, Aram So, Heuiseok Lim*</p>
                        <p class="publication-venue">Annual Conference on Human and Cognitive Language Technology (HCLT), 2024</p>
                        <div class="publication-links">
                            <a href="https://koreascience.kr/article/CFKO202404272002652.page" target="_blank">Paper</a>
                        </div>
                    </div>

                    <div class="publication-item">
                        <span class="publication-year">ACL 2024 Findings</span>
                        <h3 class="publication-title">üåü KoCommonGEN v2: A Benchmark for Navigating Korean Commonsense Reasoning Challenges in Large Language Models</h3>
                        <p class="publication-authors"><strong>Jaehyung Seo</strong>, Jaewook Lee, Chanjun Park, SeongTae Hong, Seungjun Lee, Heuiseok Lim*</p>
                        <p class="publication-venue">Annual Meeting of the Association for Computational Linguistics (ACL) Findings, 2024</p>
                        <div class="publication-links">
                            <a href="https://aclanthology.org/2024.findings-acl.141/" target="_blank">Paper</a>
                        </div>
                    </div>

                    <div class="publication-item">
                        <span class="publication-year">EMNLP 2023</span>
                        <h3 class="publication-title">üåü CHEF in the Language Kitchen: A Generative Data Augmentation Leveraging Korean Morpheme Ingredients</h3>
                        <p class="publication-authors"><strong>Jaehyung Seo</strong>, Hyeonseok Moon, Jaewook Lee, Sugyeong Eo, Chanjun Park, Heuiseok Lim*</p>
                        <p class="publication-venue">Empirical Methods in Natural Language Processing (EMNLP), 2023</p>
                        <div class="publication-links">
                            <a href="https://aclanthology.org/2023.emnlp-main.367/" target="_blank">Paper</a>
                        </div>
                    </div>

                    <div class="publication-item">
                        <span class="publication-year">Knowledge-Based Systems</span>
                        <h3 class="publication-title">üåü PU-GEN: Enhancing generative commonsense reasoning for language models with human-centered knowledge</h3>
                        <p class="publication-authors"><strong>Jaehyung Seo</strong>, Dongsuk Oh, Sugyeong Eo, Chanjun Park, Kisu Yang, Hyeonseok Moon, Kinam Park, Heuiseok Lim*</p>
                        <p class="publication-venue">Knowledge-Based Systems, 2022</p>
                        <div class="publication-links">
                            <a href="https://www.sciencedirect.com/science/article/abs/pii/S0950705122009546" target="_blank">Paper</a>
                        </div>
                    </div>

                    <div class="publication-item">
                        <span class="publication-year">IEEE Access</span>
                        <h3 class="publication-title">üåü Plain Template Insertion: Korean-Prompt-Based Engineering for Few-Shot Learners</h3>
                        <p class="publication-authors"><strong>Jaehyung Seo</strong>, Hyeonseok Moon, Chanhee Lee, Sugyeong Eo, Chanjun Park, Jihoon Kim, Changwoo Chun, Heuiseok Lim*</p>
                        <p class="publication-venue">IEEE Access, 2022</p>
                        <div class="publication-links">
                            <a href="https://ieeexplore.ieee.org/document/9913979" target="_blank">Paper</a>
                        </div>
                    </div>

                    <div class="publication-item">
                        <span class="publication-year">NAACL 2022 Findings</span>
                        <h3 class="publication-title">üåü A Dog Is Passing Over The Jet? A Text-Generation Dataset for Korean Commonsense Reasoning and Evaluation</h3>
                        <p class="publication-authors"><strong>Jaehyung Seo</strong>*, Seounghoon Lee*, Chanjun Park, Yoonna Jang, Hyeonseok Moon, Sugyeong Eo, Seonmin Koo, Heuiseok Lim*</p>
                        <p class="publication-venue">North American Chapter of the ACL (NAACL) Findings, 2022</p>
                        <div class="publication-links">
                            <a href="https://aclanthology.org/2022.findings-naacl.172/" target="_blank">Paper</a>
                        </div>
                    </div>

                    <div class="publication-item">
                        <span class="publication-year">Mathematics</span>
                        <h3 class="publication-title">üåü Dense-to-Question and Sparse-to-Answer: Hybrid Retriever System for Industrial Frequently Asked Questions</h3>
                        <p class="publication-authors"><strong>Jaehyung Seo</strong>, Taemin Lee, Hyeonseok Moon, Chanjun Park, Sugyeong Eo, Imatitikua D Aiyanyo, Kinam Park, Aram So, Sungmin Ahn, Jeongbae Park*</p>
                        <p class="publication-venue">Mathematics, 2022</p>
                        <div class="publication-links">
                            <a href="https://www.mdpi.com/2227-7390/10/8/1335" target="_blank">Paper</a>
                        </div>
                    </div>

                    <div class="publication-item">
                        <span class="publication-year">HCLT 2021 üèÜ Outstanding Paper</span>
                        <h3 class="publication-title">üåü KommonGen: A Dataset for Korean Generative Commonsense Reasoning Evaluation</h3>
                        <p class="publication-authors"><strong>Jaehyung Seo</strong>, Chanjun Park, Hyeonseok Moon, Sugyeong Eo, Myunghoon Kang, Seounghoon Lee, Heuiseok Lim*</p>
                        <p class="publication-venue">Annual Conference on Human and Cognitive Language Technology (HCLT), 2021</p>
                        <div class="publication-links">
                            <a href="https://j-seo.github.io/KommonGen_-A-Dataset-for-Korean-Generative-Commonsense-Reasoning-Evaluation/" target="_blank">Paper</a>
                        </div>
                    </div>
                </div>

                <div class="text-center" style="margin-top: var(--spacing-xl);">
                    <a href="publications.html" class="btn btn-primary">View All Publications</a>
                </div>
            </div>
        </section>

    </main>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <div class="footer-content">
                <div class="footer-logo">ELION Lab</div>
                <ul class="footer-links">
                    <li><a href="index.html">Home</a></li>
                    <li><a href="about.html">About</a></li>
                    <li><a href="publications.html">Publications</a></li>
                    <li><a href="team.html">Team</a></li>
                    <li><a href="contact.html">Contact</a></li>
                </ul>
                <div class="social-links">
                    <a href="https://scholar.google.com/citations?user=V8bFAUIAAAAJ&hl=ko" target="_blank" rel="noopener noreferrer" aria-label="Google Scholar">
                        <svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor"><path d="M12 24a7 7 0 1 1 0-14 7 7 0 0 1 0 14zm0-24L0 9.5l4.838 3.94A8 8 0 0 1 12 9a8 8 0 0 1 7.162 4.44L24 9.5z"/></svg>
                    </a>
                    <a href="https://www.linkedin.com/in/jaehyungseo-elionlab" target="_blank" rel="noopener noreferrer" aria-label="LinkedIn">
                        <svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg>
                    </a>
                </div>
            </div>
            <p class="footer-copyright">
                ¬© 2026 ELION Lab. All rights reserved.
            </p>
        </div>
    </footer>

    <!-- JavaScript -->
    <script src="assets/js/main.js"></script>
</body>
</html>

